{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7061e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "model_name = \"E:\\\\models\\\\Llama-3.2-3B-Instruct\"\n",
    "token = os.getenv(\"HFTOKEN\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd9c883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khatt\\Documents\\AmazonEcho-NLP-Project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.73s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM \n",
    "from transformers import AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4fb237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    return_full_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2365d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khatt\\AppData\\Local\\Temp\\ipykernel_26268\\2838025220.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "model_name = \"E:/models/gte-small\"\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    multi_process=False,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e6720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up one level (or more depending on where your .ipynb file is)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))  # adjust if needed\n",
    "sys.path.append(project_root)\n",
    "from WebsiteScrap import WebsiteScrapper\n",
    "web = WebsiteScrapper(\"https://www.amazon.com/Amazon-Basics-Everyday-Plates-Disposable/dp/B0C2CY22B8/?_encoding=UTF8&pd_rd_w=APjaP&content-id=amzn1.sym.f2128ffe-3407-4a64-95b5-696504f68ca1&pf_rd_p=f2128ffe-3407-4a64-95b5-696504f68ca1&pf_rd_r=YXMEXN435CNCQZWD512A&pd_rd_wg=7Izqy&pd_rd_r=3fbb0d02-8f22-4b11-ac45-f11f9ef282d6&ref_=pd_hp_d_btf_crs_zg_bs_284507&th=1\")\n",
    "dfname = web.websitename()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbf6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "envpath = \"../.env\"\n",
    "load_dotenv(dotenv_path=envpath)\n",
    "PINECONE = os.getenv(\"PINECONE\")\n",
    "pc = Pinecone(api_key=PINECONE)\n",
    "index = pc.Index(\"vectorized\")\n",
    "user_input = input(\"User: \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccdc0f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khatt\\Documents\\AmazonEcho-NLP-Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What do people thinki about the product\"\n",
    "vectorized_input = embedding_model.embed_query(user_input)\n",
    "\n",
    "context = index.query(\n",
    "    namespace=\"echo\",\n",
    "    vector=vectorized_input,\n",
    "    top_k=2,\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56631e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context['matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fd73553",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [context['matches'][i]['metadata']['text'] for i in range(len(context['matches']))]\n",
    "combinedtext = str(\".\".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ae78d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an assistant that is answer people questions regarding there userinput.\n",
    "You are also provided context from a source that relates to the userinput\n",
    "Please think and answer based on the userinput and the context that you are given.\n",
    "Also provide the answer in a json format\n",
    "{\"userinput\":{},\n",
    " \"context\" : \n",
    "\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f06f260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Awesome product! However, it does take time for Alexa to recognize other language when asked to play Spanish music and after a while she’ll turn off by it self..I really enjoy itI'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ebac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an Amazon AI Assistant that answers customer questions using reviews from a vector database. \"\n",
    "            \"Answer the question using only the reviews provided below, and limit your response to 100 words.\\n\\n\"\n",
    "            f\"Reviews: {combinedtext}\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What do people think about the product\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cf39840",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m(context\u001b[38;5;241m=\u001b[39mcombinedtext)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'format'"
     ]
    }
   ],
   "source": [
    "messages.format(context=combinedtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03ec025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ce8f163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'system',\n",
       "    'content': 'You are an Amazon AI Assistant that answers customer questions using context from a vector database. Answer the question using only the context provided below, and limit your response to 100 words.\\n\\nContext: Awesome product! However, it does take time for Alexa to recognize other language when asked to play Spanish music and after a while she’ll turn off by it self..I really enjoy itI'},\n",
       "   {'role': 'user', 'content': 'What do people think about the product'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Based on the context, it seems that the product (likely an Amazon Echo speaker) is generally well-liked. The user calls it an \"Awesome product\" and mentions they \"really enjoy it\". However, there is a concern about the product\\'s performance, specifically its ability to recognize and play music in multiple languages, including Spanish. Some users may experience issues with the device turning off after a while, but this doesn\\'t seem to detract from the overall positive sentiment about the product.'}]}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb6de1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, it seems that the product (likely an Amazon Echo speaker) is generally well-liked. The user calls it an \"Awesome product\" and mentions they \"really enjoy it\". However, there is a concern about the product's performance, specifically its ability to recognize and play music in multiple languages, including Spanish. Some users may experience issues with the device turning off after a while, but this doesn't seem to detract from the overall positive sentiment about the product.\n"
     ]
    }
   ],
   "source": [
    "print(output[0]['generated_text'][2]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d89412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an assistant that is answer people questions regarding there userinput.\n",
      "What do people thinki about the product:\n",
      "You are also provided context from a source that relates to the userinput\n",
      "Awesome product! However, it does take time for Alexa to recognize other language when asked to play Spanish music and after a while she’ll turn off by it self..I really enjoy itI\n",
      "Please think and answer based on the userinput and the context that you are given.\n",
      "You will be asked to provide a name for the product.\n",
      "I need to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I need to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I want to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I want to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I want to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I want to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I want to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I want to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I want to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I want to know what do you think about something.\n",
      "I have already answered this question.\n",
      "I want to know what do you think about something.\n",
      "I have already answered this question.\n",
      "2 The first of these, the \"new\" user interface, is a set of tools that,\n"
     ]
    }
   ],
   "source": [
    "print(answer[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9782e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from WebsiteScrap import WebsiteScrapper\n",
    "from embeddedstuff import Embedded\n",
    "from transformers import AutoModelForCausalLM \n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "class llmmodel:\n",
    "    def __init__(self,user_input,url):\n",
    "        self.model_name=\"E:\\\\models\\\\pleasRAG\"\n",
    "        self.user_input = user_input\n",
    "        self.url = url\n",
    "\n",
    "    def llmmodel(self):\n",
    "        model = AutoModelForCausalLM.from_pretrained(self.model_name)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            return_full_text=True\n",
    "        )\n",
    "\n",
    "        return pipe\n",
    "        \n",
    "\n",
    "    def context(self):\n",
    "        web = WebsiteScrapper\n",
    "        emb = Embedded\n",
    "        embedding_model=emb.load_embmodel()\n",
    "        dfname = web.websitename\n",
    "        PINECONE = os.getenv(\"PINECONE\")\n",
    "        pc = Pinecone(api_key=PINECONE)\n",
    "        index = pc.Index(\"amazon\")\n",
    "        \n",
    "        vectorized_input = embedding_model.embed_query(self.user_input)\n",
    "        context = index.query(\n",
    "            namespace=dfname,\n",
    "            vector=vectorized_input,\n",
    "            top_k=2,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        combinedcontext = [context['matches'][i]['metadata']['text'] for i in range(len(context['matches']))]\n",
    "        combinedcontext=str(\".\".join(combinedcontext))\n",
    "        return combinedcontext\n",
    "\n",
    "    def feedback(self):\n",
    "        contextfromdb = self.context()\n",
    "        prompt = \"\"\"What do yu think about the product based on the reviews \n",
    "        {reviews}\"\"\"\n",
    "        answer = pipe(prompt.format(review = contextfromdb))\n",
    "\n",
    "        return answer[0]['generatedtext']\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
