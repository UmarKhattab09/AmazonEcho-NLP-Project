{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe7bac7-1d35-4b40-80b0-a612b095d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7f333ca9-aadf-4c93-b1be-566b3fb0a891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pageurl</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Color</th>\n",
       "      <th>User Verified</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Review Useful Count</th>\n",
       "      <th>Configuration Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Declaration Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>Not great speakers</td>\n",
       "      <td>Black</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo Dot</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Great little gagit</td>\n",
       "      <td>White</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>9/26/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo Dot</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Awesome!</td>\n",
       "      <td>Awesome üëèüèΩ</td>\n",
       "      <td>White</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>9/8/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo Dot</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love my Echo</td>\n",
       "      <td>Black</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>10/19/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo Dot</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great device</td>\n",
       "      <td>Black</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>9/17/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo Dot</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pageurl        Title  \\\n",
       "0  https://www.amazon.com/All-New-Amazon-Echo-Dot...  Three Stars   \n",
       "1  https://www.amazon.com/All-New-Amazon-Echo-Dot...   Four Stars   \n",
       "2  https://www.amazon.com/All-New-Amazon-Echo-Dot...     Awesome!   \n",
       "3  https://www.amazon.com/All-New-Amazon-Echo-Dot...   Five Stars   \n",
       "4  https://www.amazon.com/All-New-Amazon-Echo-Dot...   Five Stars   \n",
       "\n",
       "          Review Text Review Color      User Verified Review Date  \\\n",
       "0  Not great speakers        Black  Verified Purchase   10/3/2017   \n",
       "1  Great little gagit        White  Verified Purchase   9/26/2017   \n",
       "2          Awesome üëèüèΩ        White  Verified Purchase    9/8/2017   \n",
       "3        Love my Echo        Black  Verified Purchase  10/19/2017   \n",
       "4        Great device        Black  Verified Purchase   9/17/2017   \n",
       "\n",
       "   Review Useful Count Configuration Text  Rating Declaration Text  \n",
       "0                  NaN           Echo Dot       3              NaN  \n",
       "1                  NaN           Echo Dot       4              NaN  \n",
       "2                  NaN           Echo Dot       5              NaN  \n",
       "3                  NaN           Echo Dot       5              NaN  \n",
       "4                  NaN           Echo Dot       5              NaN  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Documents/Amazon Echo 2 Reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88ea71c-968a-4a88-9167-e2238b369dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\khatt\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\khatt\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\khatt\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\khatt\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\khatt\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\khatt\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45316bde-b03f-45e3-98b0-cf99db240094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Awesome', 'üëèüèΩ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = df['Review Text']\n",
    "CorpusList=[]\n",
    "test = word_tokenize(Corpus[2])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316236cb-94c8-44aa-836e-d01907425312",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting Sentence into Word\n",
    "from nltk.tokenize import word_tokenize\n",
    "for review in df['Review Text']:\n",
    "    test = word_tokenize(str(review))\n",
    "    test =[word.lower() for word in test]\n",
    "    CorpusList.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870d2f5a-baa5-42b6-8a7c-ae3bc51c7b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome', 'üëèüèΩ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusList[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37827f5-2942-4a69-a4a1-048111fc9ff6",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "- Process to reduce a word to it's word stem. Or Roots of words known to LEMMA.\n",
    "\n",
    "#### Techniques\n",
    "- Porter Stemmer  \n",
    "- RegexP Stemmer ----> You need to provide the data you want to remove,requires alot of time.\n",
    "- SnowBall Stemmer --- > Better Tecnique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71f0587-b31a-4c49-9a76-12dc9c4c0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porter Stemmer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6601395d-d1b5-4372-a5bf-d86d60ac460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming= PorterStemmer()\n",
    "\n",
    "stemmed_words = []\n",
    "for words in CorpusList:\n",
    "    stemmed_wordsss = [stemming.stem(word) for word in words]\n",
    "    stemmed_words.append(stemmed_wordsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd4c4f8-b214-4ee2-82bf-17a97030e84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesom', 'üëèüèΩ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d5f5acf-95be-4efe-a988-a9c83840972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SnowBall Stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "sbs=SnowballStemmer('english') #---> Many Languages available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f3c5db-09b5-4acb-af74-58fccb6d094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SnowballStem = []\n",
    "for words in CorpusList:\n",
    "    stem_word = [stemming.stem(word) for word in words]\n",
    "    SnowballStem.append(stem_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095f783e-1027-4bcf-a6c4-075d9a2a41e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesom', 'üëèüèΩ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SnowballStem[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee69b0-dd1c-4bcc-9d74-e5f42e0b4a33",
   "metadata": {},
   "source": [
    "## Stemming ----> Can not be used for Chatbots, and more complex stuff\n",
    "### Solution : Lemmatization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c990b51-52c4-470d-a70e-03ec4c520708",
   "metadata": {},
   "source": [
    "### Wordnet Lemmatizer ----> IS like stemming, output is lemma, which is a root word ( Eating ----> eat, Goes----> Go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a192bc-5023-4021-80f8-9cc65c92e9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['awesome', 'product', '!', 'however', ',', 'it', 'does', 'take', 'time', 'for', 'alexa', 'to', 'recognize', 'other', 'language', 'when', 'asked', 'to', 'play', 'spanish', 'music', 'and', 'after', 'a', 'while', 'she', '‚Äô', 'll', 'turn', 'off', 'by', 'it', 'self', '.']\n",
      "Lemmatized: ['awesome', 'product', '!', 'however', ',', 'it', 'does', 'take', 'time', 'for', 'alexa', 'to', 'recognize', 'other', 'language', 'when', 'asked', 'to', 'play', 'spanish', 'music', 'and', 'after', 'a', 'while', 'she', '‚Äô', 'll', 'turn', 'off', 'by', 'it', 'self', '.']\n"
     ]
    }
   ],
   "source": [
    "##### from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "CorpusList3 = CorpusList[6]\n",
    "print(\"Original:\", CorpusList3)\n",
    "\n",
    "lemmatized = [lemmatizer.lemmatize(word, pos='a') for word in CorpusList3]\n",
    "print(\"Lemmatized:\", lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aa2afe6-da3b-4125-b8a7-123bfb63fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmalist=[]\n",
    "for words in CorpusList:\n",
    "    lemma_word = [lemmatizer.lemmatize(word,pos=\"a\") for word in words]\n",
    "    lemmalist.append(stem_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97012ec7-a7c0-42ab-be34-1fb1edff6087",
   "metadata": {},
   "source": [
    "### STOPWORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "571c2cb3-5792-454b-8d2e-6d8a42beefbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29cc2ef-da59-4d7c-a83e-c3a8cdc31dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('C:/Users/khatt/AppData/Roaming/nltk_data/corpora/stopwords/english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "06e72c57-94ce-4800-80b8-52f01b475773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Awesome product!',\n",
       " 'However, it does take time for Alexa to recognize other language when asked to play Spanish music and after a while she‚Äôll turn off by it self.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "sentence = nltk.sent_tokenize(str(Corpus[6]))\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c279b908-521e-4bde-8543-644bd51bff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply StopWords and filter and then apply stemming\n",
    "for i in range(len(sentence)):\n",
    "    words = nltk.word_tokenize(sentence[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentence[i]= ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d7ee25d-94c8-4c86-a492-ea223d032433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesom product !',\n",
       " 'howev , take time alexa recogn languag ask play spanish music ‚Äô turn self .']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "38dd1841-e389-4531-9da8-a21e53b679d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply StopWords and filter and then apply stemming\n",
    "sentence = nltk.sent_tokenize(str(Corpus[6]))\n",
    "sentence\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')\n",
    "for i in range(len(sentence)):\n",
    "    words = nltk.word_tokenize(sentence[i])\n",
    "    words = [snowball.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentence[i]= ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b61e23e7-9f34-4faf-bde3-10ba78f3b444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesom product !',\n",
       " 'howev , take time alexa recogn languag ask play spanish music ‚Äô turn self .']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "937888cc-21bf-4930-a13c-b412003c55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bcf6faec-4732-4867-b779-e20e3dcf3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply StopWords and filter and then apply stemming\n",
    "sentence = nltk.sent_tokenize(str(Corpus[6]))\n",
    "sentence\n",
    "### lEMMA DOESNT LOWER THE SENTENCE\n",
    "snowball = SnowballStemmer('english')\n",
    "for i in range(len(sentence)):\n",
    "    words = nltk.word_tokenize(sentence[i])\n",
    "    words = [lemmatizer.lemmatize(word.lower(),pos=\"v\") for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentence[i]= ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b8cc912-b058-4d45-ba62-0089fb076f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome product !',\n",
       " 'however , take time alexa recognize language ask play spanish music ‚Äô turn self .']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e982f570-6673-497f-990d-1d00e21fe7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perception_tagger: Package\n",
      "[nltk_data]     'averaged_perception_tagger' not found in index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perception_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "582d0924-2f77-4bd1-b4c0-b37fa80da988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('However', 'RB'), (',', ','), ('it', 'PRP'), ('does', 'VBZ'), ('take', 'VB'), ('time', 'NN'), ('for', 'IN'), ('Alexa', 'NNP'), ('to', 'TO'), ('recognize', 'VB'), ('other', 'JJ'), ('language', 'NN'), ('when', 'WRB'), ('asked', 'VBN'), ('to', 'TO'), ('play', 'VB'), ('Spanish', 'JJ'), ('music', 'NN'), ('and', 'CC'), ('after', 'IN'), ('a', 'DT'), ('while', 'NN'), ('she', 'PRP'), ('‚Äô', 'VBZ'), ('ll', 'JJ'), ('turn', 'VB'), ('off', 'RP'), ('by', 'IN'), ('it', 'PRP'), ('self', 'PRP'), ('.', '.')]\n",
      "[('However', 'RB'), (',', ','), ('it', 'PRP'), ('does', 'VBZ'), ('take', 'VB'), ('time', 'NN'), ('for', 'IN'), ('Alexa', 'NNP'), ('to', 'TO'), ('recognize', 'VB'), ('other', 'JJ'), ('language', 'NN'), ('when', 'WRB'), ('asked', 'VBN'), ('to', 'TO'), ('play', 'VB'), ('Spanish', 'JJ'), ('music', 'NN'), ('and', 'CC'), ('after', 'IN'), ('a', 'DT'), ('while', 'NN'), ('she', 'PRP'), ('‚Äô', 'VBZ'), ('ll', 'JJ'), ('turn', 'VB'), ('off', 'RP'), ('by', 'IN'), ('it', 'PRP'), ('self', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = nltk.sent_tokenize(str(Corpus[6]))\n",
    "sentence\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(sentence)):\n",
    "    words = nltk.word_tokenize(sentence[i])\n",
    "    words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "    #sentence[i]= ' '.join(words)\n",
    "    pos_tag = nltk.pos_tag(word)\n",
    "    print(pos_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
